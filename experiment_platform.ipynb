{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import gamma\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import gennorm\n",
    "\n",
    "import time as time\n",
    "import csv\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import autograd.numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_probability as tfp #sample from a generalized normal distribution\n",
    "\n",
    "from confint import confint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 #1000, 10000\n",
    "\n",
    "dist = \"gamma\"\n",
    "# dist = \"gaussian\"\n",
    "# dist = \"chisq\"\n",
    "# dist = \"uniform\"\n",
    "# dist = \"gennorm\"\n",
    "\n",
    "alpha = 0.1 #confidence level 1 - alpha\n",
    "\n",
    "thread_num = 4 #number of threads #64, 40, 13 for n=10000, 1000, and 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n == 100:\n",
    "    opt_pts_ratio = 1\n",
    "else:\n",
    "    opt_pts_ratio = 0.3\n",
    "\n",
    "if dist == \"uniform\":\n",
    "    kappa = 4.0\n",
    "else:\n",
    "    kappa = 8.0\n",
    "\n",
    "if dist == \"gamma\":\n",
    "    M = 7.0\n",
    "elif dist == \"gaussian\":\n",
    "    M = 12.0\n",
    "elif dist == \"uniform\":\n",
    "    M = 5.0\n",
    "elif dist == \"chisq\" or dist == \"gennorm\":\n",
    "    M = 8.0\n",
    "else:\n",
    "    M = 10.0\n",
    "\n",
    "if dist == \"gaussian\":\n",
    "    tau_max = 1e5\n",
    "else:\n",
    "    tau_max = 1e3\n",
    "    \n",
    "max_iters = 50\n",
    "min_iters = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times = 2\n",
    "\n",
    "results_to_save = {}\n",
    "is_save = True\n",
    "\n",
    "run_time_ave = 0\n",
    "num_nan_repeat = 0\n",
    "num_acc_nan_repeat = 0\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "mmddyyhhmm = (\"%d_%d_%d_%d_%d\" % (now.month, now.day, now.year, now.hour, now.minute))\n",
    "part_of_out_fn = dist + \"_n_\" + str(n) + \"_uid_\" + mmddyyhhmm\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repeat in range(repeat_times):\n",
    "    if (dist == \"gaussian\"):\n",
    "        X = np.random.randn(n)\n",
    "    elif (dist == \"gamma\"):\n",
    "        X = np.random.gamma(shape=1.0, size=n)\n",
    "    elif (dist == \"chisq\"):\n",
    "        X = np.random.chisquare(df=3, size=n)\n",
    "    elif(dist == \"uniform\"):\n",
    "        X = np.random.uniform(low=-10, high=10, size=n)\n",
    "    elif(dist == \"mixture\"):\n",
    "        n_minus1 = n / 2\n",
    "        n_plus1 = n - n_minus1\n",
    "        X = np.concatenate([-2 + np.random.randn(n_minus1), 2 + np.random.randn(n_plus1)])\n",
    "    elif (dist == \"gennorm\"):\n",
    "        tfd = tfp.distributions\n",
    "        tf_dist = tfd.GeneralizedNormal(loc=0, scale=1.0, power=4.0)\n",
    "        X = tf_dist.sample(sample_shape=(n), seed=repeat).numpy()\n",
    "    else:\n",
    "        print(\"ERROR: unsupported distribution\")\n",
    "\n",
    "    X = np.sort(X)\n",
    "    conf_int = confint(X, alpha, opt_pts_ratio=opt_pts_ratio)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    conf_int.compute_pw_conf_ints(thread_num=thread_num, M=M, tau_max=tau_max, kappa=kappa, \n",
    "                                  max_iters=max_iters, min_iters=min_iters, verbose=False)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    run_time_ave += (t1 - t0) / repeat_times\n",
    "    num_acc_nan_repeat += conf_int.num_nans\n",
    "    if conf_int.num_nans != 0:\n",
    "        num_nan_repeat += 1\n",
    "    \n",
    "    if len(conf_int.idxes_of_design_pts_to_opt) <= 1:\n",
    "        continue\n",
    "\n",
    "    results_to_save[dist + str(repeat) + \"_sample_pts\"] = X\n",
    "    results_to_save[dist + str(repeat) + \"_design_pts\"] = X[conf_int.idxes_of_design_pts]\n",
    "    results_to_save[dist + str(repeat) + \"_opt_design_pts\"] = conf_int.opt_pts\n",
    "    results_to_save[dist + str(repeat) + \"_lo\"] = conf_int.low_opt_pts\n",
    "    results_to_save[dist + str(repeat) + \"_hi\"] = conf_int.high_opt_pts\n",
    "#     results_to_save[dist + str(repeat) + \"_improved_lo\"] = conf_int.improved_lo_opt_pts\n",
    "    \n",
    "    results_to_save[dist + str(repeat) + \"_extended_x\"] = conf_int.opt_int_pts\n",
    "    results_to_save[dist + str(repeat) + \"_extended_lo\"] = conf_int.low_opt_int_pts\n",
    "    results_to_save[dist + str(repeat) + \"_extended_hi\"] = conf_int.high_opt_int_pts\n",
    "    \n",
    "    results_to_save[dist + str(repeat) + \"_run_time\"] = t1 - t0\n",
    "    results_to_save[dist + str(repeat) + \"_failure_num\"] = conf_int.num_nans\n",
    "    results_to_save[dist + str(repeat) + \"_failure_design_pts\"] = conf_int.failure_design_pts\n",
    "    \n",
    "    print(\"trial\", repeat, \"run_time\", t1 - t0, \"failure_num\", conf_int.num_nans, \n",
    "          \"failure_design_pts\", conf_int.failure_design_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of total nans =\", num_acc_nan_repeat)\n",
    "print(\"number of repetitions containing nans =\", num_nan_repeat)\n",
    "print(\"ave run time =\", run_time_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = \"result_data/coverage_90/pkl/\" # directory to save file\n",
    "if is_save:\n",
    "    pickle.dump(results_to_save, open(ff + \"data_%s.pkl\" % (part_of_out_fn), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
